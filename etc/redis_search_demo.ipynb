{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf48a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5f64918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "from redis.client import Redis\n",
    "from redis.commands.search.field import TextField, VectorField\n",
    "from redis.exceptions import ResponseError\n",
    "import numpy as np\n",
    "from redis.commands.search.query import Query\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from textwrap import dedent\n",
    "from typing import Generator, Tuple\n",
    "from IPython.display import display, HTML\n",
    "from embeddings import Embeddings\n",
    "from embedding_storage.redis_storage import RedisEmbeddingStorage\n",
    "from embedding_storage.pg_storage import PostgresEmbeddingStorage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1816e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fact(text):\n",
    "    display(HTML(f'<div style=\"background-color: #00ff00;\">FACT! <pre>{text}</pre></div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f1999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path().absolute() / '..' / 'dev-config.json', 'r') as f:\n",
    "    CONFIG = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bdc9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    MORE = 'MORE_INFO_NEEDED'\n",
    "    \n",
    "    def __init__(self, *, config, embeddings):\n",
    "        self._config = config\n",
    "        self._embeddings = embeddings\n",
    "        \n",
    "        self._chat0 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=config['openai_api_key'], max_tokens=1200, model_kwargs={'temperature': 0})\n",
    "        self._chat1 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=config['openai_api_key'], max_tokens=1200, model_kwargs={'temperature': 1.0})\n",
    "        self._system_prompt = dedent(\n",
    "            f\"\"\"\n",
    "            I am a helpful assistant with access to memory.\n",
    "            Before answering a question, I ABSOLUTELY MUST access my memory by doing the folowing:\n",
    "                * I write `{self.MORE}`: QUERY, where QUERY is what I feel missing from my knowledge.\n",
    "            I never use the same QUERY twice.\n",
    "            Never use the same query twice, always come up with something new.\n",
    "            Remeber that we can do it more than once to find an answer.\n",
    "            \"\"\".strip() + '\\n'\n",
    "        )\n",
    "        self.reset()\n",
    "        \n",
    "    def _ask_chat(self, lst: list) -> str:\n",
    "        print('---')\n",
    "        for x in lst:\n",
    "            print(f'[{type(x).__name__}]')\n",
    "            print(x.content)\n",
    "        print('---')\n",
    "        print('')\n",
    "        \n",
    "        return self._chat0(lst)\n",
    "        \n",
    "    def __call__(self, text) -> str:\n",
    "        return self.say(text)\n",
    "    \n",
    "    def _info_requests_message(self, info_requests: list) -> AIMessage:\n",
    "        if info_requests:\n",
    "            return AIMessage(content='There are the things I ask previously:\\n{}'.format('\\n'.join(\n",
    "                f'  * {self.MORE}: {m}' for m in info_requests\n",
    "            )))\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def _facts_message(self, facts: list) -> AIMessage:\n",
    "        if facts:\n",
    "            return AIMessage(content='This is what I remembered:\\n{}'.format('\\n'.join(\n",
    "                f'  * {f}' for f in facts\n",
    "            )))\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def _trim(self, messages):\n",
    "        available = 3000\n",
    "        for m in messages:\n",
    "            if len(m.content) <= available:\n",
    "                yield m\n",
    "                available -= len(m.content)\n",
    "            else:\n",
    "                m_copy = m.copy()\n",
    "                m_copy.content = m.content[:available]\n",
    "                yield m_copy\n",
    "                available = 0\n",
    "                \n",
    "            if not available:\n",
    "                break\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        self._history = []\n",
    "    \n",
    "    def say(self, text, facts: list = None, info_requests: list = None, depth=0) -> str:\n",
    "        if facts is None:\n",
    "            facts = []\n",
    "        if info_requests is None:\n",
    "            info_requests = []\n",
    "        \n",
    "        to_send = [\n",
    "            AIMessage(content=self._system_prompt),\n",
    "            HumanMessage(content=text),\n",
    "        ]\n",
    "        for m in (self._info_requests_message(info_requests), self._facts_message(facts)):\n",
    "            if m is not None:\n",
    "                to_send.append(m)\n",
    "        to_send = list(self._trim(to_send))\n",
    "        response = self._ask_chat(to_send)\n",
    "        response_text = response.content\n",
    "        \n",
    "        if response_text.startswith(self.MORE) and depth < 2:\n",
    "            request = response_text[len(self.MORE) + 2:]\n",
    "            print(f'[*] New REQUEST! {request}')\n",
    "            if request not in info_requests:\n",
    "                info_requests.append(request)\n",
    "                new_facts = False\n",
    "                docs = self._embeddings.knn(request, k=2)\n",
    "                print(f'DOCS {len(docs)}')\n",
    "                for text in docs:\n",
    "                    if text not in facts:\n",
    "                        facts.append(text)\n",
    "                        new_facts = True\n",
    "                        display_fact(text)\n",
    "                        #print(f'[*] New fact! {text}')\n",
    "                if new_facts:\n",
    "                    return self.say(text, depth=depth+1, facts=facts, info_requests=info_requests)\n",
    "                else:\n",
    "                    print('[*] No new facts')\n",
    "            else:\n",
    "                print('[*] Duplicate request')\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2e6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rds = Redis(host='localhost', port=6379, db=0)\n",
    "redis_storage = RedisEmbeddingStorage('examplegpt', redis=rds)\n",
    "postgres_storage = PostgresEmbeddingStorage.from_config('examplegpt', config=CONFIG['pg'])\n",
    "e = Embeddings(config=CONFIG, version=VERSION, storage=postgres_storage)\n",
    "chat = Chat(config=CONFIG, embeddings=e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c139e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.reset(); chat('Чем махнул Каратаев в повести Тургенева \"Бежин луг\"?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75ff9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexer:\n",
    "    PATTERN = \"Part of document called {title}. Starts from char {offset} out of {length}.\\n---\\n\\n{chunk}\"\n",
    "    \n",
    "    def __init__(self, *, embeddings: Embeddings, title: str, text: str):\n",
    "        self._e = embeddings\n",
    "        self._title = title\n",
    "        self._text = text\n",
    "        \n",
    "        self._window = 10000\n",
    "        self._overlap = 1000\n",
    "        \n",
    "        assert self._window > self._overlap\n",
    "        \n",
    "    def _chunks(self) -> Generator[Tuple[int, str], None, None]:\n",
    "        offset = 0\n",
    "        length = len(self._text)\n",
    "        while True:\n",
    "            if length - offset < 1.5 * self._window:\n",
    "                yield (offset, self._text[offset:])\n",
    "                return\n",
    "            else:\n",
    "                yield (offset, self._text[offset : offset + self._window])\n",
    "                offset += self._window - self._overlap\n",
    "        \n",
    "    def index(self) -> None:\n",
    "        for offset, chunk in self._chunks():\n",
    "            text_to_index = self.PATTERN.format(title=self._title, offset=offset, length=len(self._text), chunk=chunk)\n",
    "            self._e.add(text_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1844a7ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgramLimitExceeded",
     "evalue": "index row size 7544 exceeds btree version 4 maximum 2704 for index \"examplegpt_texts_pkey\"\nDETAIL:  Index row references tuple (0,1) in relation \"examplegpt_texts\".\nHINT:  Values larger than 1/3 of a buffer page cannot be indexed.\nConsider a function index of an MD5 hash of the value, or use full text indexing.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProgramLimitExceeded\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     text \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      3\u001b[0m indexer \u001b[38;5;241m=\u001b[39m Indexer(embeddings\u001b[38;5;241m=\u001b[39me, title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mБежин луг, из цикла \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЗаписки охотника\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m, text\u001b[38;5;241m=\u001b[39mtext)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m offset, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chunks():\n\u001b[1;32m     27\u001b[0m     text_to_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPATTERN\u001b[38;5;241m.\u001b[39mformat(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_title, offset\u001b[38;5;241m=\u001b[39moffset, length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text), chunk\u001b[38;5;241m=\u001b[39mchunk)\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_to_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/membot/embeddings.py:45\u001b[0m, in \u001b[0;36mEmbeddings.add\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m found\n\u001b[1;32m     44\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding(text)\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embedding\u001b[38;5;241m.\u001b[39mtobytes()\n",
      "File \u001b[0;32m~/membot/embeddings.py:33\u001b[0m, in \u001b[0;36mEmbeddings._save_embedding\u001b[0;34m(self, text, embedding)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_embedding\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m, embedding: np\u001b[38;5;241m.\u001b[39marray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_embedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[43mversion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/membot/embedding_storage/pg_storage.py:65\u001b[0m, in \u001b[0;36mPostgresEmbeddingStorage.save_embedding\u001b[0;34m(self, text, embedding, version)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pg:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pg\u001b[38;5;241m.\u001b[39mcursor() \u001b[38;5;28;01mas\u001b[39;00m c:\n\u001b[0;32m---> 65\u001b[0m         \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;43m            INSERT INTO \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_namespace\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_texts (text, embedding, version)\u001b[39;49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;43m            VALUES (%s, %s, %s)\u001b[39;49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;43m            ON CONFLICT (text) DO UPDATE\u001b[39;49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;43m                SET embedding = EXCLUDED.embedding, version = EXCLUDED.version;\u001b[39;49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;43m            \u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mProgramLimitExceeded\u001b[0m: index row size 7544 exceeds btree version 4 maximum 2704 for index \"examplegpt_texts_pkey\"\nDETAIL:  Index row references tuple (0,1) in relation \"examplegpt_texts\".\nHINT:  Values larger than 1/3 of a buffer page cannot be indexed.\nConsider a function index of an MD5 hash of the value, or use full text indexing.\n"
     ]
    }
   ],
   "source": [
    "with open('lug.txt') as f:\n",
    "    text = f.read()\n",
    "indexer = Indexer(embeddings=e, title='Бежин луг, из цикла \"Записки охотника\"', text=text)\n",
    "indexer.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc966c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
