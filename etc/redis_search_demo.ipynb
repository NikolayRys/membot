{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf48a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f64918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "import redis\n",
    "from redis.commands.search.field import TextField, VectorField\n",
    "from redis.exceptions import ResponseError\n",
    "import numpy as np\n",
    "from redis.commands.search.query import Query\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from textwrap import dedent\n",
    "from typing import Generator, Tuple\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1816e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_fact(text):\n",
    "    display(HTML(f'<div style=\"background-color: #00ff00;\">FACT! <pre>{text}</pre></div>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f1999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path().absolute() / '..' / 'dev-config.json', 'r') as f:\n",
    "    CONFIG = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    def __init__(self, index_name, *, config):\n",
    "        self._config = config\n",
    "        self._index_name = index_name\n",
    "        \n",
    "        self._open_ai_emb = OpenAIEmbeddings(openai_api_key=self._config['openai_api_key'])\n",
    "        self._redis = redis.Redis(host='localhost', port=6379, db=0)\n",
    "        \n",
    "        self._init_redis()\n",
    "        \n",
    "    def _init_redis(self):\n",
    "        try:\n",
    "            self._redis.ft(self._index_name).dropindex()\n",
    "        except ResponseError:\n",
    "            pass\n",
    "        \n",
    "        emb_field = VectorField(\n",
    "            name='embedding',\n",
    "            algorithm='HNSW',\n",
    "            attributes=dict(\n",
    "                type='FLOAT64',\n",
    "                dim=1536,\n",
    "                distance_metric='COSINE',\n",
    "            ),\n",
    "        )\n",
    "        version_field = TextField('version')\n",
    "        \n",
    "        self._redis.ft(self._index_name).create_index([\n",
    "            emb_field,\n",
    "            version_field,\n",
    "        ])\n",
    "\n",
    "\n",
    "    def _get_embedding(self, text: str) -> np.array:\n",
    "        embedding = self._open_ai_emb.embed_query(text)\n",
    "        \n",
    "        return np.array(embedding)\n",
    "    \n",
    "    def _save_embedding(self, text: str, embedding: np.array) -> bytes:\n",
    "        self._redis.hset(f\"text:{text}\", mapping = dict(\n",
    "            embedding=embedding.tobytes(),\n",
    "            text=text,\n",
    "            version=VERSION,\n",
    "        ))\n",
    "                \n",
    "    def add(self, text: str) -> np.array:\n",
    "        found = self._redis.hget(f'text:{text}', 'version')\n",
    "        if found and found == VERSION:\n",
    "            return found\n",
    "        \n",
    "        embedding = self._get_embedding(text)\n",
    "        self._save_embedding(text, embedding)\n",
    "\n",
    "        return embedding.tobytes()\n",
    "\n",
    "    def knn(self, text: str, *, k: int = 100) -> list:\n",
    "        q = (\n",
    "            Query(f\"(@version:{VERSION})=>[KNN {k} @embedding $e]\")\n",
    "            .return_field('text')\n",
    "            .return_field('__embedding_score')\n",
    "            .dialect(2)\n",
    "        )\n",
    "        result = self._redis.ft(self._index_name).search(q, query_params={\"e\": self._get_embedding(text).tobytes()})\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def close(self):\n",
    "        self._s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc9697",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chat:\n",
    "    MORE = 'MORE_INFO_NEEDED'\n",
    "    \n",
    "    def __init__(self, *, config, embeddings):\n",
    "        self._config = config\n",
    "        self._embeddings = embeddings\n",
    "        \n",
    "        self._chat0 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=config['openai_api_key'], max_tokens=1200, model_kwargs={'temperature': 0})\n",
    "        self._chat1 = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=config['openai_api_key'], max_tokens=1200, model_kwargs={'temperature': 1.0})\n",
    "        self._system_prompt = dedent(\n",
    "            f\"\"\"\n",
    "            I am a helpful assistant with access to memory.\n",
    "            Before answering a question, I ABSOLUTELY MUST access my memory by doing the folowing:\n",
    "                * I write `{self.MORE}`: QUERY, where QUERY is what I feel missing from my knowledge.\n",
    "            I never use the same QUERY twice.\n",
    "            Never use the same query twice, always come up with something new.\n",
    "            Remeber that we can do it more than once to find an answer.\n",
    "            \"\"\".strip() + '\\n'\n",
    "        )\n",
    "        self.reset()\n",
    "        \n",
    "    def _ask_chat(self, lst: list) -> str:\n",
    "        print('---')\n",
    "        for x in lst:\n",
    "            print(f'[{type(x).__name__}]')\n",
    "            print(x.content)\n",
    "        print('---')\n",
    "        print('')\n",
    "        \n",
    "        return self._chat0(lst)\n",
    "        \n",
    "    def __call__(self, text) -> str:\n",
    "        return self.say(text)\n",
    "    \n",
    "    def _info_requests_message(self, info_requests: list) -> AIMessage:\n",
    "        if info_requests:\n",
    "            return AIMessage(content='There are the things I ask previously:\\n{}'.format('\\n'.join(\n",
    "                f'  * {self.MORE}: {m}' for m in info_requests\n",
    "            )))\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def _facts_message(self, facts: list) -> AIMessage:\n",
    "        if facts:\n",
    "            return AIMessage(content='This is what I remembered:\\n{}'.format('\\n'.join(\n",
    "                f'  * {f}' for f in facts\n",
    "            )))\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def _trim(self, messages):\n",
    "        available = 3000\n",
    "        for m in messages:\n",
    "            if len(m.content) <= available:\n",
    "                yield m\n",
    "                available -= len(m.content)\n",
    "            else:\n",
    "                m_copy = m.copy()\n",
    "                m_copy.content = m.content[:available]\n",
    "                yield m_copy\n",
    "                available = 0\n",
    "                \n",
    "            if not available:\n",
    "                break\n",
    "    \n",
    "    def reset(self) -> None:\n",
    "        self._history = []\n",
    "    \n",
    "    def say(self, text, facts: list = None, info_requests: list = None, depth=0) -> str:\n",
    "        if facts is None:\n",
    "            facts = []\n",
    "        if info_requests is None:\n",
    "            info_requests = []\n",
    "        \n",
    "        to_send = [\n",
    "            AIMessage(content=self._system_prompt),\n",
    "            HumanMessage(content=text),\n",
    "        ]\n",
    "        for m in (self._info_requests_message(info_requests), self._facts_message(facts)):\n",
    "            if m is not None:\n",
    "                to_send.append(m)\n",
    "        to_send = list(self._trim(to_send))\n",
    "        response = self._ask_chat(to_send)\n",
    "        response_text = response.content\n",
    "        \n",
    "        if response_text.startswith(self.MORE) and depth < 2:\n",
    "            request = response_text[len(self.MORE) + 2:]\n",
    "            print(f'[*] New REQUEST! {request}')\n",
    "            if request not in info_requests:\n",
    "                info_requests.append(request)\n",
    "                new_facts = False\n",
    "                docs = self._embeddings.knn(request, k=2).docs\n",
    "                print(f'DOCS {len(docs)}')\n",
    "                for e in docs:\n",
    "                    if e.text not in facts:\n",
    "                        facts.append(e.text)\n",
    "                        new_facts = True\n",
    "                        display_fact(e.text)\n",
    "                        #print(f'[*] New fact! {e.text}')\n",
    "                if new_facts:\n",
    "                    return self.say(text, depth=depth+1, facts=facts, info_requests=info_requests)\n",
    "                else:\n",
    "                    print('[*] No new facts')\n",
    "            else:\n",
    "                print('[*] Duplicate request')\n",
    "\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2e6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embeddings('examplegpt', config=CONFIG)\n",
    "chat = Chat(config=CONFIG, embeddings=e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c139e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.reset(); chat('Чем махнул Каратаев в повести Тургенева \"Бежин луг\"?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Indexer:\n",
    "    PATTERN = \"Part of document called {title}. Starts from char {offset} out of {length}.\\n---\\n\\n{chunk}\"\n",
    "    \n",
    "    def __init__(self, *, embeddings: Embeddings, title: str, text: str):\n",
    "        self._e = embeddings\n",
    "        self._title = title\n",
    "        self._text = text\n",
    "        \n",
    "        self._window = 10000\n",
    "        self._overlap = 1000\n",
    "        \n",
    "        assert self._window > self._overlap\n",
    "        \n",
    "    def _chunks(self) -> Generator[Tuple[int, str], None, None]:\n",
    "        offset = 0\n",
    "        length = len(self._text)\n",
    "        while True:\n",
    "            if length - offset < 1.5 * self._window:\n",
    "                yield (offset, self._text[offset:])\n",
    "                return\n",
    "            else:\n",
    "                yield (offset, self._text[offset : offset + self._window])\n",
    "                offset += self._window - self._overlap\n",
    "        \n",
    "    def index(self) -> None:\n",
    "        for offset, chunk in self._chunks():\n",
    "            text_to_index = self.PATTERN.format(title=self._title, offset=offset, length=len(self._text), chunk=chunk)\n",
    "            self._e.add(text_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Embeddings('examplegpt', config=CONFIG)\n",
    "with open('lug.txt') as f:\n",
    "    text = f.read()\n",
    "indexer = Indexer(embeddings=e, title='Бежин луг, из цикла \"Записки охотника\"', text=text)\n",
    "indexer.index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc966c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
